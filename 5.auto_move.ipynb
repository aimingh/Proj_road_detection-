{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2, time, traitlets\n",
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "import ipywidgets.widgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(img):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    gray = cv2.GaussianBlur(gray, (7,7),0)\n",
    "    return gray\n",
    "\n",
    "def thresholding(img_gray):\n",
    "    _, img_th = cv2.threshold(img_gray,np.average(img_gray)-40,255,cv2.THRESH_BINARY)\n",
    "    img_th2 = cv2.adaptiveThreshold(img_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,21,15)\n",
    "    img_th3 = np.bitwise_and(img_th, img_th2)\n",
    "    img_th4 = cv2.subtract(img_th2, img_th3)\n",
    "    for i in range(5):\n",
    "        img_th4 = cv2.medianBlur(img_th4, 5)\n",
    "    return img_th4\n",
    "\n",
    "def mask_roi(img_th, roi):\n",
    "    mask = np.zeros_like(img_th)\n",
    "    cv2.fillPoly(mask, np.array([roi], np.int32), 255)\n",
    "    masked_image = cv2.bitwise_and(img_th, mask)\n",
    "    return masked_image\n",
    "\n",
    "def drawContours(img_rgb, contours):\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        cv2.drawContours(img_rgb, [cnt], 0, (255,0,0), 1)\n",
    "    return img_rgb\n",
    "\n",
    "def approximationContour(img, contours, e=0.02):\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        epsilon = e*cv2.arcLength(cnt, True)\n",
    "        approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "        cv2.drawContours(img, [approx], 0, (0,255,255), 2)\n",
    "    return img\n",
    "\n",
    "def rectwithname(img, contours, e=0.02):\n",
    "    result = img.copy()\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        epsilon = e*cv2.arcLength(cnt, True)\n",
    "        approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "        cv2.rectangle(result,(x,y),(x+w,y+h),(255,0,255),2)\n",
    "    return result\n",
    "\n",
    "def find_midptr(contours):\n",
    "    center_ptrs = []\n",
    "    e=0.01\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        center_ptr = [y, x + 0.5*w,]\n",
    "        center_ptrs.append(center_ptr)\n",
    "    center_ptrs = np.array(center_ptrs)\n",
    "    return center_ptrs\n",
    "\n",
    "def find_midlane(center_ptrs, center_image_point):\n",
    "    L2_norm = np.linalg.norm((center_ptrs - center_image_point), axis=1, ord=2)\n",
    "    loc = np.where(L2_norm==L2_norm.min())[0][0]\n",
    "    midlane = center_ptrs[loc]\n",
    "    return midlane\n",
    "\n",
    "def find_degree(center_image_point, midlane):\n",
    "    return 57.2958*np.arctan((midlane[1] - center_image_point[1])/(center_image_point[0] - midlane[0]))\n",
    "\n",
    "def search_road(img, seta):\n",
    "    img_gray = preprocessing(img)\n",
    "    img_th = thresholding(img_gray)\n",
    "    w_roi = 2\n",
    "#     roi = [(0, height),(0, height/2-50), (width, height/2-50),(width, height),]\n",
    "    roi = [(width/4, height),(width/4+20+w_roi*seta, height/4), (3*width/4-20+w_roi*seta, height/4),(3*width/4, height),]\n",
    "    img_roi = mask_roi(img_th, roi)\n",
    "#     img_roi = img_th\n",
    "    \n",
    "    kernel = np.ones((5,3),np.uint8)\n",
    "    img_cl = cv2.morphologyEx(img_roi,cv2.MORPH_CLOSE, np.ones((5,5),np.uint8),iterations=4)\n",
    "    img_op = cv2.morphologyEx(img_cl,cv2.MORPH_OPEN, np.ones((5,5),np.uint8),iterations=2)\n",
    "    \n",
    "    cannyed_image = cv2.Canny(img_op, 300, 500)\n",
    "    contours, _ = cv2.findContours(cannyed_image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    center_ptrs = find_midptr(contours)\n",
    "    \n",
    "#     input_image.value = bgr8_to_jpeg(cannyed_image)\n",
    "    center_image_point = [height-1, width/2-1]\n",
    "    midlane = find_midlane(center_ptrs, center_image_point)\n",
    "    seta = find_degree(center_image_point, midlane)\n",
    "    \n",
    "    cv2.line(img,(int(center_image_point[1]), int(center_image_point[0])),(int(midlane[1]),int(midlane[0])),(0,0,255),3)\n",
    "    cv2.putText(img, f'{seta}', (int(midlane[1]), int(midlane[0])-5), cv2.FONT_HERSHEY_COMPLEX, 0.5,(255, 0, 0), 1)\n",
    "    return img, img_op, seta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = Robot()\n",
    "left_slider = widgets.FloatSlider(description='left', min=-1.0, max=1.0, step=0.01, orientation='vertical')\n",
    "right_slider = widgets.FloatSlider(description='right', min=-1.0, max=1.0, step=0.01, orientation='vertical')\n",
    "left_link = traitlets.link((left_slider, 'value'), (robot.left_motor, 'value'))\n",
    "right_link = traitlets.link((right_slider, 'value'), (robot.right_motor, 'value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 224\n",
    "height = 224\n",
    "camera = Camera.instance()\n",
    "input_image = widgets.Image(format='jpeg', width=width, height=height)\n",
    "result1 = widgets.Image(format='jpeg', width=width, height=height)\n",
    "result2 = widgets.Image(format='jpeg', width=width, height=height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_box = widgets.HBox([input_image, result1, result2, left_slider, right_slider], layout=widgets.Layout(align_self='center'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb20bea708a546daaa70f5a039431e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', height='224', width='224'), Image(value=b'', format='jpeg', hei…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(image_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.23214122047051\t\t118471114172024252831343740414247485354585962717477808384858891929699100104107\t110113116119"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "seta = 0\n",
    "while True:\n",
    "    img = camera.value\n",
    "    try:\n",
    "        img_result, img_op, seta = search_road(img, seta)\n",
    "        print(seta, end='\\t')\n",
    "        result1.value = bgr8_to_jpeg(img_result)\n",
    "        result2.value = bgr8_to_jpeg(img_op)\n",
    "        pw = 1.2\n",
    "        w = (seta/90)\n",
    "        left_power = pw*(0.1 + w*0.1)\n",
    "        right_power = pw*(0.1 - w*0.1)\n",
    "        robot.set_motors(left_power, right_power)\n",
    "#         time.sleep(0.5)\n",
    "#         robot.stop()\n",
    "    except:\n",
    "        print('not Found',  end='\\r')\n",
    "        robot.stop()\n",
    "    input_image.value = bgr8_to_jpeg(img)\n",
    "    if count ==120:\n",
    "        break\n",
    "    else:\n",
    "        count = count +1\n",
    "        print(count, end='\\r')\n",
    "        time.sleep(0.1)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (0,) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-29bda33c972f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimg_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_road\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresult1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbgr8_to_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-d5b9320d4f63>\u001b[0m in \u001b[0;36msearch_road\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m#     input_image.value = bgr8_to_jpeg(cannyed_image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mcenter_image_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mmidlane\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_midlane\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter_ptrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter_image_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mseta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_degree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter_image_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidlane\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-d5b9320d4f63>\u001b[0m in \u001b[0;36mfind_midlane\u001b[0;34m(center_ptrs, center_image_point)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_midlane\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter_ptrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter_image_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mL2_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter_ptrs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcenter_image_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL2_norm\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mL2_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mmidlane\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcenter_ptrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (0,) (2,) "
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "img = camera.value\n",
    "img_result, img_op, seta = search_road(img)\n",
    "print(seta, end='\\t')\n",
    "result1.value = bgr8_to_jpeg(img_result)\n",
    "result2.value = bgr8_to_jpeg(img_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7ba7529de149d9976a1c6efe567050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', height='224', width='224'), Image(value=b'', format='jpeg', hei…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "width = 224\n",
    "height = 224\n",
    "input_img = widgets.Image(format='jpeg', width=width, height=height)\n",
    "result11 = widgets.Image(format='jpeg', width=width, height=height)\n",
    "result12 = widgets.Image(format='jpeg', width=width, height=height)\n",
    "result13 = widgets.Image(format='jpeg', width=width, height=height)\n",
    "result14 = widgets.Image(format='jpeg', width=width, height=height)\n",
    "image_box2 = widgets.HBox([input_img, result11, result12, result13, result14], layout=widgets.Layout(align_self='center'))\n",
    "display(image_box2)\n",
    "# display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "seta = 0\n",
    "w_roi = 2\n",
    "while True:\n",
    "    img = camera.value\n",
    "    img_gray = preprocessing(img)\n",
    "    img_th = thresholding(img_gray)\n",
    "    roi = [(0, height),(width/4+20+w_roi*seta, height/4), (3*width/4-20+w_roi*seta, height/4),(width, height),]\n",
    "    img_roi = mask_roi(img_th, roi)\n",
    "#     img_roi = img_th\n",
    "    \n",
    "    kernel = np.ones((5,3),np.uint8)\n",
    "    img_cl = cv2.morphologyEx(img_roi,cv2.MORPH_CLOSE, np.ones((5,5),np.uint8),iterations=4)\n",
    "    img_op = cv2.morphologyEx(img_cl,cv2.MORPH_OPEN, np.ones((5,5),np.uint8),iterations=2)\n",
    "    \n",
    "    cannyed_image = cv2.Canny(img_op, 300, 500)\n",
    "    contours, _ = cv2.findContours(cannyed_image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    img_approx = approximationContour(img, contours, e=0.02)\n",
    "    img_approx_rect = rectwithname(img, contours, e=0.01)  \n",
    "    \n",
    "    center_ptrs = find_midptr(contours)\n",
    "    \n",
    "    center_image_point = [height-1, width/2-1]\n",
    "    try:\n",
    "        midlane = find_midlane(center_ptrs, center_image_point)\n",
    "        seta = find_degree(center_image_point, midlane)\n",
    "\n",
    "        cv2.line(img,(int(center_image_point[1]), int(center_image_point[0])),(int(midlane[1]),int(midlane[0])),(0,0,255),3)\n",
    "        cv2.putText(img, f'{seta}', (int(midlane[1]), int(midlane[0])-5), cv2.FONT_HERSHEY_COMPLEX, 0.5,(255, 0, 0), 1)\n",
    "    except:\n",
    "        print('Not Found seta')\n",
    "        \n",
    "#     center_ptrs = []\n",
    "#     e=0.01\n",
    "#     for cnt in contours:\n",
    "#         x, y, w, h = cv2.boundingRect(cnt)\n",
    "#         center_ptr = [y, x + 0.5*w,]\n",
    "#         center_ptrs.append(center_ptr)\n",
    "#     center_ptrs = np.array(center_ptrs)\n",
    "#     L2_norm = np.linalg.norm((center_ptrs - center_image_point), axis=1, ord=2)\n",
    "#     loc = np.where(L2_norm==L2_norm.min())[0][0]\n",
    "#     midlane = center_ptrs[loc]\n",
    "    \n",
    "    result_img1 = img_th\n",
    "    result_img2 = img_cl\n",
    "    result_img3 = img_op\n",
    "    result_img4 = img\n",
    "    \n",
    "    #show results\n",
    "    result_imgs = [result_img1, result_img2, result_img3, result_img4]\n",
    "    result_values = [result11, result12, result13, result14]\n",
    "    for result_img, result_value in zip(result_imgs, result_values):\n",
    "#         if len(result_img.shape)==2:\n",
    "#             result_img = np.stack((result_img,)*3,2)\n",
    "        result_value.value = bgr8_to_jpeg(result_img)\n",
    "    input_img.value = bgr8_to_jpeg(img_gray)\n",
    "    \n",
    "    if count ==10:\n",
    "        break\n",
    "    else:\n",
    "        count = count +1\n",
    "#         print(count, end='  ')\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
